# -*- coding: utf-8 -*-
"""model_kafka.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fezg27AFQq6QDuwPciVEaOOL2ac32iJW
"""

from flask import Flask, request, jsonify
import numpy as np
import joblib
from kafka import KafkaProducer, KafkaConsumer
import json
import threading

app = Flask(__name__)

# Kafka Configuration
KAFKA_BROKER = "localhost:9092"
KAFKA_TOPIC = "flask_topic"

# Initialize Kafka Producer
producer = KafkaProducer(
    bootstrap_servers=KAFKA_BROKER,
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

# Load the Machine Learning Model
model = joblib.load("Linear.pkl")

# List to store consumed messages
consumed_messages = []

# Kafka Consumer Function
def start_consumer():
    consumer = KafkaConsumer(
        KAFKA_TOPIC,
        bootstrap_servers=KAFKA_BROKER,
        value_deserializer=lambda v: json.loads(v.decode('utf-8')),
        auto_offset_reset="earliest",
        group_id="flask-consumer-group"
    )
    for message in consumer:
        print(f"Consumed: {message.value}")
        consumed_messages.append(message.value)

# Start Kafka Consumer in a Separate Thread
threading.Thread(target=start_consumer, daemon=True).start()

# Prediction Endpoint
@app.route("/predict", methods=["POST"])
def predict():
    try:
        data = request.get_json()

        # Required Features for Prediction
        required_features = ["Unit Price", "Quantity", "Tax 5%", "Cogs",
                             "Gross Margin Percentage", "Gross Income", "Rating"]

        # Check if all required features are present
        for fe in required_features:
            if fe not in data:
                return jsonify({"error": f"{fe} is missing from the request body"}), 400

        # Extract Features
        features = [
            data["Unit Price"],
            data["Quantity"],
            data["Tax 5%"],
            data["Cogs"],
            data["Gross Margin Percentage"],
            data["Gross Income"],
            data["Rating"]
        ]

        # Convert to NumPy Array and Reshape
        features = np.array(features).reshape(1, -1)

        # Validate Feature Shape
        if features.shape[1] != len(required_features):
            return jsonify({"error": "You are missing some features"}), 400

        # Make Prediction
        prediction = model.predict(features)

        # Prepare Response
        response = {
            "prediction": prediction.tolist(),
            "result": float(round(prediction[0], 2)),
            "message": "success"
        }

        # Send Data to Kafka
        producer.send(KAFKA_TOPIC, data)
        producer.flush()

        return jsonify(response), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# Endpoint to Get Consumed Messages
@app.route("/consume", methods=["GET"])
def consume_message():
    return jsonify({"consumed_messages": consumed_messages}), 200

# Main Function to Run the App
if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0")